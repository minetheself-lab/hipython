{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6fa3ce5",
   "metadata": {},
   "source": [
    "# 타이타닉 생존자 머신러닝 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc28a2b5",
   "metadata": {},
   "source": [
    "## 1. 테스트 환경 셋팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2167ffcb",
   "metadata": {},
   "source": [
    "### 라이브러리 불러오기\n",
    "import pandas as pd 타이타닉 데이터는 표 데이터이기 때문에 pandas를 불러온다.  \n",
    "from sklearn.model_selection import train_test_split 학습용, 테스트용 분리를 위해   \n",
    "from sklearn.metrics import accuracy_score 예측이 맞았는지 수치 확인을 위해. 맞춘개수/전체개수. 혼동행렬 기준으로 (TP+TN)/전체값  \n",
    "from sklearn.preprocessing import LabelEncoder 문자를 숫자로 바꾸기 위해 문자라벨을 숫자로 변환한다. 중복을 제거하여 정렬하고 0부터 차례대로 번호를  부여한다.  \n",
    "from sklearn.metrics import confusion_matrix 어디서 틀렸는지 알기 위해   \n",
    "(예측1은 P, 0은 N, 실제와 비교해 맞으면T, 틀리면F)  \n",
    "- 예측이 1인데 실제를 확인해보니 1=> P가 맞아서 T, TP  \n",
    "- 예측이 1인데 실제를 확인해보니 0 => P가 틀려서F, FP \n",
    "- 예측이 0인데 실제를 확인해보니 0 => N이 맞아서 T, TN \n",
    "- 예측이 0인데 실제를 확인해보니 1 => N이 맞아서 F, FN\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "- 정밀도: 내가 1P이라고 예측한 것들 중에서 실제로 1P인 비율. TP/(TP+FP) 값\n",
    "- 재현율: 실제로 1P인데 예측에서 1P로 맞춘 비율 TP/(TP+FN)값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ece59b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c704a91",
   "metadata": {},
   "source": [
    "## 2. 데이터 불러오고 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1616fdff",
   "metadata": {},
   "source": [
    "### 판다스 import 및 데이터프레임 정의\n",
    "url을 변수에 담고 url에 있는 csv 파일을 열어서 RAM으로 읽어온다.  \n",
    "이것을 df 변수에 저장하고 상단 2개 목록만 불러온다.  \n",
    "만약 csv 파일을 저장하고 싶으면 df.to_csv(\"titanic.csv\", index=False) index번호 안붙임  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee4fab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e6b63",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcd7c22",
   "metadata": {},
   "source": [
    "### 결측치 처리\n",
    "fillna 함수를 정의하되 입력 파라미터는 df로 정의  \n",
    "df.copy() 원본데이터를 복사해서 편집하기 위해  \n",
    "컬럼값 'Age'는 숫자이다. 빈값을 평균값으로 채워 'Age'에 저장  \n",
    "컬럼값 'Cabin', 'Embarked'은 문자형임으로 문자 N으로 채운다.  \n",
    "컬럼값 'Fare'를 숫자0으로 채운다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5540032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna(df):\n",
    "    df = df.copy()  # 명시적 복사\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "    df['Cabin'] = df['Cabin'].fillna('N')\n",
    "    df['Embarked'] = df['Embarked'].fillna('N')\n",
    "    df['Fare'] = df['Fare'].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ffb058",
   "metadata": {},
   "source": [
    "### 열삭제 처리\n",
    "axis=0은 행방향, 1은 열방향. 열방향으로 3개 칼럼을 삭제함.  \n",
    "이 전처리를 반복해서 쓸 수 있으므로 함수 정의  \n",
    "df는 로컬변수이므로 안에서만 사용가능  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64152fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_features(df):\n",
    "    return df.drop(['PassengerId', 'Name', 'Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6765234",
   "metadata": {},
   "source": [
    "### 문자형 데이터를 숫자형으로 변환\n",
    "Cabin에서 문자열의 첫글자만 사용해서 cabin에 저장  \n",
    "features-숫자로 바꿔야할 컬럼목록이다. sex, embarked는 범주개수가 단순. 반면 cabin은 고유값이 너무 많아서 cabin만 따로 처리함  \n",
    "features 3개 컬럼을 1개씩 돌려가며 반복.하되 LabelEncoder로 숫자를 부여한다.  \n",
    "컬럼 1개를 가져와서, \n",
    "fit을 써서 값을 불러오고 번호표가 매핑되어 있다. transform으로 번호표로 바꿔준다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5b8d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_features(df):\n",
    "    df = df.copy()\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        df[feature] = le.fit_transform(df[feature])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12047cb5",
   "metadata": {},
   "source": [
    "### 함수들 한번에 처리\n",
    "결측치 처리한 함수, 불필요한 칼럼 제거한 함수, 숫자로 변환한 함수를 묶어서 하나의 함수로 처리  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b7f8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6977e53",
   "metadata": {},
   "source": [
    "### 4개 모델을 함수로 묶음\n",
    "두개의 파라미터 입력값이 있는 함수 정의, 함수정의할때는 실행되지 않는다. 함수값을 호출할 때 실행된다.  \n",
    "y_test는 실제 정답, pred는 예측값, 두개의 값을 입력해서 혼동행렬, 정확도, 정밀도, 재현율 계산  \n",
    "혼동행렬: TP: 맞게 생존 예측, FP: 틀리게 생존 예측, FN: 놓친 생존자, TN: 맞게 사망 예측  \n",
    "정확도: 전체개수중 맞춘 개수  \n",
    "정밀도: 생존으로 예측했던 사람중 실제 생존자수  \n",
    "재현율: 실제 생존자 중 몇명을 맞췄는가  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3abd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "\n",
    "    print(confusion)\n",
    "    print('*'*20)\n",
    "    print(accuracy, precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e5d9b",
   "metadata": {},
   "source": [
    "### 전처리 데이터를 변수로 저장\n",
    "머신러닝 모델이 학습할 수 있는 데이터  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "384aac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = transform_features(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfdc0b7",
   "metadata": {},
   "source": [
    "### 입력과 정답을 분리 \n",
    "Survived 칼럼을 정답값으로 정의하고 따로 y에 저장  \n",
    "나머지 칼럼을 입력값으로 정의하고 x에 저장  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f52b5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf319a6",
   "metadata": {},
   "source": [
    "## 4. 데이터분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354a001f",
   "metadata": {},
   "source": [
    "### 학습용, 테스트용 데이터 나누기\n",
    "x학습용, x테스트, y학습, y테스트로 나누다.  \n",
    "입력데이터, 정답 데이터 구분, 학습용과 테스트를 0.2, 즉 20%는 테스트, 나머지 80%는 학습용  \n",
    "랜덤값 0. 임의값 지정. 이렇게 하지 않으면 돌릴때마다 랜덤값이 다르다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2ba090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df,\n",
    "                                                    y_titanic_df,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc342f",
   "metadata": {},
   "source": [
    "## 5. 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841a06c6",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀\n",
    "- klearn.linear_model모듈에서 로지스틱 회귀 클래스를 가져온다.입력 변수(X)를 받아서 특정 클래스에 속할 확률을 예측하고, 확률이 일정 기준(보통 0.5) 이상이면 1, 미만이면 0 등으로 분류한다.  \n",
    "- lr_clf라는 이름으로 로지스틱 회귀 모델 객체 생성, 최대 반복회수는 2000번. 최적 가중치 찾기 위해  \n",
    "- fit: 학습 데이터 X_train과 정답 y_train을 이용해 로지스틱 회귀 모델이 최적의 가중치와 편향을 학습하도록 하는 명령  \n",
    "- 학습되지 않은 X_test데이터가 회귀모델에서 얼마나 잘 예측하는지 해보세요.  \n",
    "- 4개 모델을 묶은 get_clf_eval함수안에 실제 정답인 y_test와 모델이 옟측한 값을 비교해주세요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dcb598d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92 18]\n",
      " [16 53]]\n",
      "********************\n",
      "0.8100558659217877 0.7464788732394366 0.7681159420289855\n"
     ]
    }
   ],
   "source": [
    "#로지스틱회귀 분류모델 생성\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter=2000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "\n",
    "#정확도, 정밀도, 재현율\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadcf1da",
   "metadata": {},
   "source": [
    "## 6. 단순가설의 분류기를 이용한 성능 기준 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d0237",
   "metadata": {},
   "source": [
    "### 나만의 상자모델 만듬\n",
    "### 표안에 초기값0, sex값 넣음\n",
    "- sklearn.base는 모델을 만들때 기본틀을 제공하는 모듈. \n",
    "- BaseEstimator는 모델의 뼈대를 제공함. 이를 상속하면 사이킷런 스타일 규칙을 따른다.  \n",
    "- 사이킷런에서 쓸 수 있는 나만의 빈 상자 모델을 만들었고, 그 안에 함수를 만듬.  \n",
    "- 함수안에 입력값X, 정답값y를 보고 학습시킨다.  \n",
    "- 클래스안에서 변수나 함수를 사용할 때 항상 self를 붙여야 한다.  \n",
    "- 이 코드는 더미 분류기 이다. fit에서 학습이 없고 바로 pass, predict에서 단순규칙만 사용. 일종의 기준점. '시험공부 안하고 찍었을 때 평균점수'를 뜻한다.  \n",
    "- X.shape[0]는 행수, X.shape[1]는 열수  \n",
    "- np.zeros(행수, 열수) : 지정한 행,열 표로 만들되 그 안을 0으로 채워라  \n",
    "- 행수는 X.shape[0]만큼, 열은 1열. X.shape[0] 행 × 1 열의 표 만들어짐. 초기값 0으로 들어가 있음  \n",
    "- for: X.shape[0]는 X의 행수, range는 0부터 숫자 시퀀스, for i in는 숫자 시퀀스를 하나씩 i 변수에 담아 반복실행  \n",
    "- if~: X에서 Sex 컬럼, i행 값이 1이면 남성,i행에 0을 넣고, 여성이면 1값을 넣는다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b29bad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "  def fit(self, X, y):\n",
    "    pass\n",
    "\n",
    "  def predict(self, X):\n",
    "    pred = np.zeros((X.shape[0],1))\n",
    "    for i in range(X.shape[0]): #테스트데이터 갯수 만큼 \n",
    "      if X['Sex'].iloc[i] == 1:\n",
    "        pred[i]=0\n",
    "      else :\n",
    "        pred[i]=1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a3de69",
   "metadata": {},
   "source": [
    "### 더미 분류기 생성, 학습, 예측\n",
    "- 더미 분류기 객체 생성  \n",
    "- fit~: 학습 데이터 X_train과 y_train을 모델에 전달, 학습없이 predict만 호출  \n",
    "- predict~: X_test를 이용해 모델이 규칙대로 예측한 결과를 my_pred 배열에 저장  \n",
    "- 실제 정답 y_test, 예측과 비교하여 맞춘비율 정확도 계산  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e884a522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7877094972067039"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "my_pred = myclf.predict(X_test)\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c5c4a8",
   "metadata": {},
   "source": [
    "## 7. 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433dff5",
   "metadata": {},
   "source": [
    "### 랜덤포레스트, KNN import\n",
    "- RandomForestClassifier : 분류(Classification) 문제를 해결하는 모델  \n",
    "- ensemble = 여러 개의 작은 나무(결정 기준)를 만들어서, 가장 많은 나무가 선택한 답을 최종 예측  \n",
    "- KNeighborsClassifier = K-최근접 이웃(K-Nearest Neighbors, KNN) 기반의 분류 모델  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51abf1ec",
   "metadata": {},
   "source": [
    "### 랜덤포레스트 결정트리개수, KNN 이웃개수 지정하여 학습, 예측\n",
    "n_estimators 결정트리개수 100개, n_neighbors 이웃개수 5개  \n",
    "랜덤포레스트, KNN 학습 (학습 입력데이터 features, 정답데이터 target)  \n",
    "학습용 입력값과 정답값을 각각의 방법으로 학습시킨다.  \n",
    "테스트용 X값을 각각의 방법으로 예측한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a014b507",
   "metadata": {},
   "source": [
    "### 결과\n",
    "로지스틱회귀, 랜덤포레스트, KNN 정확도, 정밀도, 재현율, F1 스코어  \n",
    "F1 스코어: 정밀도와 재현율 고려한 종합점수  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc585f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "로지스틱 회귀\n",
      "========================================\n",
      "[[92 18]\n",
      " [16 53]]\n",
      "********************\n",
      "0.8100558659217877 0.7464788732394366 0.7681159420289855\n",
      "\n",
      "========================================\n",
      "랜덤포레스트\n",
      "========================================\n",
      "[[99 11]\n",
      " [20 49]]\n",
      "********************\n",
      "0.8268156424581006 0.8166666666666667 0.7101449275362319\n",
      "\n",
      "========================================\n",
      "KNN\n",
      "========================================\n",
      "[[94 16]\n",
      " [31 38]]\n",
      "********************\n",
      "0.7374301675977654 0.7037037037037037 0.5507246376811594\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 모델 생성 및 학습\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "print(\"=\" * 40)\n",
    "print(\"로지스틱 회귀\")\n",
    "print(\"=\" * 40)\n",
    "get_clf_eval(y_test, pred)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"랜덤포레스트\")\n",
    "print(\"=\" * 40)\n",
    "get_clf_eval(y_test, rf_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"KNN\")\n",
    "print(\"=\" * 40)\n",
    "get_clf_eval(y_test, knn_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba0c7a0",
   "metadata": {},
   "source": [
    "### 점수의 의미\n",
    "1에 가까울 수록 성능이 좋다. 모델이 실제 정답과 얼마나 잘 맞았는지를 보여주는 점수  \n",
    "- Accuracy(정확도): 전체 예측 중 맞춘 비율이 높다. 10문제 중 맞춘 문제 수가 많음  \n",
    "- Precision(정밀도): 모델이 맞다고 한 것 중 실제로 맞은 비율이 높다. 내가 맞다고 표시한 답이 대부분 맞음  \n",
    "- Recall(재현율): 실제 맞는 것 중 모델이 맞춘 비율이 높다. 실제 정답을 거의 놓치지 않음  \n",
    "- F1 Score: Precision과 Recall이 모두 높다. 정확도와 놓치지 않은 정도를 동시에 잘 달성  \n",
    "- F1 점수 = 0.9 → 모델이 생존/사망을 거의 정확히 맞추고, 동시에 놓치는 경우도 거의 없음  \n",
    "- F1 점수 = 0.5 → 모델이 정확히 맞춘 것도 적고, 놓치는 경우도 많음  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_edu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
